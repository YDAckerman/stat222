---
title: "Individual Project Summary 3/13"
author: "Yoni Ackerman"
output: pdf_document
bibliography: library.bib
---

```{r, echo = false}
nc_files <- list.files(paste0("/accounts/grad/yoni/Documents/Stat222/",
                              "data/cmip5-ng/"),
                       recursive = TRUE, full.names = TRUE)

nc <- nc_files[[1]]
dat <- nc_open(nc)
lat <- ncvar_get(dat, "lat")
lon <- ncvar_get(dat, "lon")
dat <- ncvar_get(dat, "tas")
```

# Introduction

Rapidly progressing, anthropogenic climate change is
not only real, but arguably the most dangerous threat facing human societies
and global stability [@UCS2000]. In order to predict spatio-temporal
changes in global climate under a variety of scenarios and assumptions, climate
researchers developed computational models to emulate long-term atmosphere and ocean
dynamics. There is hope that these models can provide policy and decision makers with
predictive tools for climate change preparedness and mitigation (see, for example,
[link](http://climateprospectus.org/)). A statistical hurdle, however, impedes this
goal: model uncertainty. Much research
has gone into understanding and limiting the sources of model uncertainty
[@Hawkins2009, @Brohan2006, @Regier2013].
Despite this progress, there remains a deeper concern
regarding model independence and its effect on uncertainty quantification.

The models often share both code modules as well as the
biases of their implementors. Thus the models and their outputs do not represent
independent draws
from a space of "all possible future climate trajectories". Thus, agreement in model
predictions does not grant greater certainty [@Larose2005]. To skirt this
issue, Knutti et al describe a method to build consensus models from combinations of
model prediction that takes into account their interdependence. By then placing a
prior over all possible consensus models, independent samples of "possible future 
climates" can be drawn and used in analyses [@Knutti2010].

There are still a number of problems with this approach. For one, it doesn't directly
address the original central problem: the models are not
independent, so model agreement doesn't imply higher certainty. Beyond the lingering
problems with prediction, we argue that there are shortcomings with the methods used
in this result. In particular, each model is originally expressed - even before EOF
(PCA) - in a severely limited form. Only 6 of the original climate variables are used
in model comparison. This appears to be due to a computational constraint (at least,
it certainly in on our machines). We would first like to attempt to address this
issue.

# Data Summary

We are using Coupled Model Intercomparison Project (CMIP5) data
made available by ETH Institute for Atmospheric and Climate Science, as well as
observational data gathered
(according to [@Knutti2010] Table 1). We have access to: the observational dataset,
as well as data from a total of 46 models, 36 variables, under 10 different scenarios,
combined using 47 different ensembles, and each available in daily/monthly/annual
aggregations and in two spatial coordinate grids (one provided by the model source,
and another interpolated to a 2.5 by 2.5 degree grid).

To get an idea of the data in their most basic, time-series form, see Figure 1. This
plot shows time series data for surface temperature taken from the ACCESS1-3
model, under the historicalGHG scenario, resampled with r1i1p1 ensemble, and grided
to 2.5 by 2.5 degrees.

```{r, echo = FALSE, fig.cap = fig$cap("Figure 1", "Basic Timeseries Data")}
tmp <- data.frame(t = seq_along(dat[72, 32,]), x1 = dat[72, 32,],
                  x2 = dat[5, 10,], lonlat = "(178.75, -11.25)",
                  LonLat = "(11.25, -66.25)")

ggplot(tmp) +
    geom_line(aes(x = t, y = x1, color = lonlat)) +
    geom_line(aes(x = t, y = x2, color = LonLat))
```

# Issues

# Current Results

# Anticipated Directions

# References
